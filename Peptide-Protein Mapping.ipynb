{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peptide-Protein Mapping\n",
    "\n",
    "This notebook processes peptide and protein data to map peptides to their positions within protein sequences. The output includes peptide sequences with their surrounding amino acids.\n",
    "\n",
    "---\n",
    "\n",
    "## Workflow\n",
    "\n",
    "1. Load input files (proteins, peptides)\n",
    "2. Create mapping dictionary\n",
    "3. Search for peptide matches within protein sequences\n",
    "4. Extract peptide context\n",
    "5. Merge results and save output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5bf6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define file paths and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4ac162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and output file paths\n",
    "input_proteins_file = 'PGs_processed_250522.tsv'\n",
    "input_peptides_file = 'precursors_all samples, filtered, normalized_250522.tsv'\n",
    "output_file = 'results.csv'\n",
    "final_output_file = 'precursors_all samples, filtered, normalized_250522_Q.tsv'\n",
    "\n",
    "# Chunk size for processing large protein files\n",
    "chunk_size = 500\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load peptide data and create mapping dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2025bc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load peptides with Protein.Group information\n",
    "peptides_df = pd.read_csv(input_peptides_file, sep='\\t', encoding='UTF-8', usecols=['Stripped.Sequence', 'Protein.Group'])\n",
    "peptides_df_complete = pd.read_csv(input_peptides_file, sep='\\t', encoding='UTF-8')\n",
    "\n",
    "# Remove any rows with missing values in essential columns\n",
    "peptides_df = peptides_df.dropna(subset=['Stripped.Sequence', 'Protein.Group'])\n",
    "\n",
    "# Create dictionary mapping Protein.Group to peptide sequences\n",
    "peptides_dict = peptides_df.groupby('Protein.Group')['Stripped.Sequence'].unique().to_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define peptide matching function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115532da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(protein_sequence, peptide_sequence):\n",
    "    \"\"\"\n",
    "    Search for peptide sequences within the given protein sequence.\n",
    "    Handles ambiguous amino acids using regex substitutions.\n",
    "    \n",
    "    Returns:\n",
    "        A string of matching peptides with surrounding amino acids, or None if no match found.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for peptide in peptide_sequence:\n",
    "           # Handle ambiguous amino acids by replacing with regex patterns\n",
    "        peptide = peptide.replace('Z', '[QE]').replace('B', '[DN]').replace('J', '[LI]').replace('X', '.')\n",
    "        for match in re.finditer(peptide, protein_sequence):\n",
    "            start = match.start()\n",
    "            end = match.end()\n",
    "            matched = protein_sequence[start:end]\n",
    "            previous = protein_sequence[start-1] if start > 0 else '.'\n",
    "            following = protein_sequence[end] if end < len(protein_sequence) else '.'\n",
    "            results.append(f'{previous}.{matched}.{following}')\n",
    "    return (', '.join(results) if results else None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process protein data in chunks and search for matching peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f28a1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read proteins file in chunks to handle large files efficiently\n",
    "proteins_df = pd.read_csv(input_proteins_file, sep='\\t', encoding='UTF-8', usecols=['Protein.Group', 'UniProt_Sequence'], chunksize=chunk_size)\n",
    "\n",
    "# Process each chunk\n",
    "for i, chunk in enumerate(proteins_df):\n",
    "      # Handle multiple UniProt sequences per protein group\n",
    "    chunk['UniProt_Sequence'] = chunk['UniProt_Sequence'].str.split(';')\n",
    "    chunk = chunk.explode('UniProt_Sequence')\n",
    "\n",
    "    # Apply peptide matching function row by row\n",
    "    def process_row(row):\n",
    "        group = row['Protein.Group']\n",
    "        seq = row['UniProt_Sequence']\n",
    "        peptides = peptides_dict.get(group, [])\n",
    "        return find(seq, peptides)\n",
    "\n",
    "    chunk['results'] = chunk.apply(process_row, axis=1)\n",
    "    chunk = chunk[chunk['results'].notna()]\n",
    "    chunk.to_csv(output_file, mode='a', index=False, header=(i == 0))\n",
    "\n",
    "    print(f\"Processed rows {i * chunk_size}-{(i + 1) * chunk_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract stripped peptide sequences and prepare final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb06df5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load intermediate results\n",
    "df = pd.read_csv(output_file)\n",
    "\n",
    "# Clean up results column\n",
    "df['results'] = df['results'].astype(str).str.replace('\"', '').str.split(',')\n",
    "df = df.explode('results')\n",
    "df['results'] = df['results'].str.strip()\n",
    "df = df[df['results'] != '']\n",
    "df = df[['results']].drop_duplicates()\n",
    "\n",
    "# Extract stripped peptide sequence (remove surrounding amino acids)\n",
    "df['Stripped.Sequence'] = df['results'].str.extract(r'\\.([A-Z]+)\\.')\n",
    "df.columns = ['Stripped.Sequence_Q', 'Stripped.Sequence']\n",
    "df = df[['Stripped.Sequence', 'Stripped.Sequence_Q']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge enriched data with original peptide dataset and save final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1476ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with complete peptide dataset\n",
    "df_final = pd.merge(peptides_df_complete, df, on='Stripped.Sequence', how='left')\n",
    "\n",
    "# Save final dataset\n",
    "df_final.to_csv(final_output_file, sep='\\t', index=False)\n",
    "print(f\"Final table saved to '{final_output_file}'.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
